{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aecebbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_schema = order_id int, order_date date, customer_id int, order_status string\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "order_id int, order_date date, customer_id int, order_status string"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val order_schema = \"order_id int, order_date date, customer_id int, order_status string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf306bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "order_df = [order_id: int, order_date: date ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: date ... 2 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val order_df = spark.read.format(\"csv\").schema(order_schema).load(\"/public/trendytech/orders/orders_1gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bcaceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.createOrReplaceTempView(\"order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7671db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [('order_id * 1) AS new_order_id#13, 'order_status]\n",
      "+- 'Filter ('order_id < 200)\n",
      "   +- 'SubqueryAlias `__auto_generated_subquery_name`\n",
      "      +- 'Project ['order_id, 'customer_id, 'order_status]\n",
      "         +- 'Filter ('order_id < 500)\n",
      "            +- 'UnresolvedRelation `order`\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "new_order_id: int, order_status: string\n",
      "Project [(order_id#0 * 1) AS new_order_id#13, order_status#3]\n",
      "+- Filter (order_id#0 < 200)\n",
      "   +- SubqueryAlias `__auto_generated_subquery_name`\n",
      "      +- Project [order_id#0, customer_id#2, order_status#3]\n",
      "         +- Filter (order_id#0 < 500)\n",
      "            +- SubqueryAlias `order`\n",
      "               +- Relation[order_id#0,order_date#1,customer_id#2,order_status#3] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [(order_id#0 * 1) AS new_order_id#13, order_status#3]\n",
      "+- Filter ((isnotnull(order_id#0) && (order_id#0 < 500)) && (order_id#0 < 200))\n",
      "   +- Relation[order_id#0,order_date#1,customer_id#2,order_status#3] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [(order_id#0 * 1) AS new_order_id#13, order_status#3]\n",
      "+- *(1) Filter ((isnotnull(order_id#0) && (order_id#0 < 500)) && (order_id#0 < 200))\n",
      "   +- *(1) FileScan csv [order_id#0,order_status#3] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://m01.itversity.com:9000/public/trendytech/orders/orders_1gb.csv], PartitionFilters: [], PushedFilters: [IsNotNull(order_id), LessThan(order_id,500), LessThan(order_id,200)], ReadSchema: struct<order_id:int,order_status:string>\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select order_id*1 as new_order_id,order_status from (select order_id,customer_id\n",
    ",order_status from order where order_id<500) where order_id<200\n",
    "\"\"\").explain(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9b78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

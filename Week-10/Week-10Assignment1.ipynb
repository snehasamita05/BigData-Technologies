{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ce4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "appName(\"Sneha Spark Session\").\\\n",
    "config(\"spark.shuffle.useOldFetchProtocol\", 'true'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7102a6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sneha Spark Session</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f768dc8d7b8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c2ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_schema = 'order_id long, order_date date, customer_id long, order_status string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e256bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = spark.read.\\\n",
    "format(\"csv\").\\\n",
    "schema(order_schema).\\\n",
    "load(\"/public/trendytech/orders/orders_1gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35b8c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|2013-07-25|      11599|         CLOSED|\n",
      "|       2|2013-07-25|        256|PENDING_PAYMENT|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc9312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1f15a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_id</th><th>order_date</th><th>customer_id</th><th>order_status</th></tr>\n",
       "<tr><td>1</td><td>2013-07-25</td><td>11599</td><td>CLOSED</td></tr>\n",
       "<tr><td>2</td><td>2013-07-25</td><td>256</td><td>PENDING_PAYMENT</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+----------+-----------+------------+\n",
       "|order_id|order_date|customer_id|order_status|\n",
       "+--------+----------+-----------+------------+\n",
       "|   51049|2014-06-09|       4983|  PROCESSING|\n",
       "|   51050|2014-06-09|       1840|     ON_HOLD|\n",
       "+--------+----------+-----------+------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from orders limit 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f905d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_schema = \"customer_id long,customer_fname string, customer_lname string,username string, password string,address string, city string, state string, pincode long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ec7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = spark.read.format(\"csv\").schema(customer_schema).load(\"/public/trendytech/retail_db/customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f96de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+---------+---------+--------------------+-----------+-----+-------+\n",
      "|customer_id|customer_fname|customer_lname| username| password|             address|       city|state|pincode|\n",
      "+-----------+--------------+--------------+---------+---------+--------------------+-----------+-----+-------+\n",
      "|          1|       Richard|     Hernandez|XXXXXXXXX|XXXXXXXXX|  6303 Heather Plaza|Brownsville|   TX|  78521|\n",
      "|          2|          Mary|       Barrett|XXXXXXXXX|XXXXXXXXX|9526 Noble Embers...|  Littleton|   CO|  80126|\n",
      "+-----------+--------------+--------------+---------+---------+--------------------+-----------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d30d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e9a24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>customer_fname</th><th>customer_lname</th><th>username</th><th>password</th><th>address</th><th>city</th><th>state</th><th>pincode</th></tr>\n",
       "<tr><td>1</td><td>Richard</td><td>Hernandez</td><td>XXXXXXXXX</td><td>XXXXXXXXX</td><td>6303 Heather Plaza</td><td>Brownsville</td><td>TX</td><td>78521</td></tr>\n",
       "<tr><td>2</td><td>Mary</td><td>Barrett</td><td>XXXXXXXXX</td><td>XXXXXXXXX</td><td>9526 Noble Embers...</td><td>Littleton</td><td>CO</td><td>80126</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------------+--------------+---------+---------+--------------------+-----------+-----+-------+\n",
       "|customer_id|customer_fname|customer_lname| username| password|             address|       city|state|pincode|\n",
       "+-----------+--------------+--------------+---------+---------+--------------------+-----------+-----+-------+\n",
       "|          1|       Richard|     Hernandez|XXXXXXXXX|XXXXXXXXX|  6303 Heather Plaza|Brownsville|   TX|  78521|\n",
       "|          2|          Mary|       Barrett|XXXXXXXXX|XXXXXXXXX|9526 Noble Embers...|  Littleton|   CO|  80126|\n",
       "+-----------+--------------+--------------+---------+---------+--------------------+-----------+-----+-------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from customers limit 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa315b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.join(customer_df,order_df.customer_id ==customer_df.customer_id,\"inner\").write.format(\"noop\").mode(\"overwrite\").save() # broadcast Hash Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5aa7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e65cdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.join(customer_df,order_df.customer_id ==customer_df.customer_id,\"inner\").write.format(\"noop\").mode(\"overwrite\").save() # sort Merge Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c256aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.join(customer_df.hint(\"shuffle_hash\"),order_df.customer_id ==customer_df.customer_id,\"inner\").write.format(\"noop\").mode(\"overwrite\").save() # shuffled hash Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899f1a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.adaptive.enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4245d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eddf99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.adaptive.enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eabc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_schema = 'order_id long, order_date date, customer_id long, order_status string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc46212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = spark.read.\\\n",
    "format(\"csv\").\\\n",
    "schema(order_schema).\\\n",
    "load(\"/public/trendytech/orders/orders_1gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37909bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_schema = \"customer_id long,customer_fname string, customer_lname string,username string, password string,address string, city string, state string, pincode long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aba3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = spark.read.format(\"csv\").schema(customer_schema).load(\"/public/trendytech/retail_db/customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c906ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eb76e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.join(customer_df,order_df.customer_id ==customer_df.customer_id,\"inner\").write.format(\"noop\").mode(\"overwrite\").save() # sort Merge Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "019d9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.join(customer_df.hint(\"shuffle_hash\"),order_df.customer_id ==customer_df.customer_id,\"inner\").write.format(\"noop\").mode(\"overwrite\").save() # shuffle Hash Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9321e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from orders inner join customers on (orders.customer_id ==customers.customer_id)\") \\\n",
    ".write.format(\"noop\") \\\n",
    ".mode(\"overwrite\").save() # sort merge join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e3ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data = [(10, \"Raj\",\"1999\",\"100\",\"M\",2000),\n",
    "(20, \"Rahul\",\"2002\",\"200\",\"M\",2000),\n",
    "(30, \"Raghav\",\"2010\",\"100\",\"\",2000),\n",
    "(40, \"Reema\",\"2004\",\"100\",\"F\",2000),\n",
    "(50, \"Rina\",\"2008\",\"400\",\"F\",2000),\n",
    "(60, \"Rasul\",\"2014\",\"500\",\"M\",2000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f592e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_schema = [\"employee_id\",\"name\",\"doj\",\"employee_dept_id\",\"gender\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a7e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeeDf = spark.createDataFrame(data=employee_data,schema=employee_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7611521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----+----------------+------+------+\n",
      "|employee_id| name| doj|employee_dept_id|gender|salary|\n",
      "+-----------+-----+----+----------------+------+------+\n",
      "|         10|  Raj|1999|             100|     M|  2000|\n",
      "|         20|Rahul|2002|             200|     M|  2000|\n",
      "+-----------+-----+----+----------------+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeeDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "408b04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "department_data = [(\"HR\",100),\n",
    "(\"Supply\",100),\n",
    "(\"Sales\",100),\n",
    "(\"Stock\",100),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85381cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|       HR|    100|\n",
      "|   Supply|    100|\n",
      "|    Sales|    100|\n",
      "|    Stock|    100|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "department_schema = [\"dept_name\",\"dept_id\"]\n",
    "departmentDf =spark.createDataFrame(data=department_data,schema=department_schema)\n",
    "departmentDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f21e4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left_join = employeeDf.join(departmentDf,employeeDf.employee_dept_id == departmentDf.dept_id,\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ce7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+----------------+------+------+---------+-------+\n",
      "|employee_id|  name| doj|employee_dept_id|gender|salary|dept_name|dept_id|\n",
      "+-----------+------+----+----------------+------+------+---------+-------+\n",
      "|         60| Rasul|2014|             500|     M|  2000|     null|   null|\n",
      "|         10|   Raj|1999|             100|     M|  2000|       HR|    100|\n",
      "|         10|   Raj|1999|             100|     M|  2000|   Supply|    100|\n",
      "|         10|   Raj|1999|             100|     M|  2000|    Sales|    100|\n",
      "|         10|   Raj|1999|             100|     M|  2000|    Stock|    100|\n",
      "|         30|Raghav|2010|             100|      |  2000|       HR|    100|\n",
      "|         30|Raghav|2010|             100|      |  2000|   Supply|    100|\n",
      "|         30|Raghav|2010|             100|      |  2000|    Sales|    100|\n",
      "|         30|Raghav|2010|             100|      |  2000|    Stock|    100|\n",
      "|         40| Reema|2004|             100|     F|  2000|       HR|    100|\n",
      "|         40| Reema|2004|             100|     F|  2000|   Supply|    100|\n",
      "|         40| Reema|2004|             100|     F|  2000|    Sales|    100|\n",
      "|         40| Reema|2004|             100|     F|  2000|    Stock|    100|\n",
      "|         20| Rahul|2002|             200|     M|  2000|     null|   null|\n",
      "|         50|  Rina|2008|             400|     F|  2000|     null|   null|\n",
      "+-----------+------+----+----------------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_left_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ea6b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semi_join = employeeDf.join(departmentDf,employeeDf.employee_dept_id == departmentDf.dept_id,\"semi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a533c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+----------------+------+------+\n",
      "|employee_id|  name| doj|employee_dept_id|gender|salary|\n",
      "+-----------+------+----+----------------+------+------+\n",
      "|         30|Raghav|2010|             100|      |  2000|\n",
      "|         10|   Raj|1999|             100|     M|  2000|\n",
      "|         40| Reema|2004|             100|     F|  2000|\n",
      "+-----------+------+----+----------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_semi_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2654ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "departmentDf.createOrReplaceTempView(\"department_table\")\n",
    "employeeDf.createOrReplaceTempView(\"employee_table\")\n",
    "res = spark.sql(\"\"\"select * from employee_table Left Outer JOIN department_table ON \\\n",
    "employee_table.employee_dept_id == department_table.dept_id\n",
    "\"\"\")\n",
    "res = spark.sql(\"\"\"select * from employee_table SEMI JOIN department_table ON \\\n",
    "employee_table.employee_dept_id == department_table.dept_id\n",
    "\"\"\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee43e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
